{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import time as T\n",
    "import random\n",
    "import tsfel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# groq\n",
    "from groq import Groq\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"), # stored API key in virtual environment (not going to GitHub)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MakeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "time = 10\n",
    "offset = 100\n",
    "folders = [\"LAYING\",\"SITTING\",\"STANDING\",\"WALKING\",\"WALKING_DOWNSTAIRS\",\"WALKING_UPSTAIRS\"]\n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "combined_dir = os.path.join(\"Combined\")\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Train Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Train\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_train.append(df.values)\n",
    "        y_train.append(classes[folder])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Test Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Final Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# USE THE BELOW GIVEN DATA FOR TRAINING and TESTING purposes\n",
    "\n",
    "# concatenate the training and testing data\n",
    "X = np.concatenate((X_train,X_test))\n",
    "y = np.concatenate((y_train,y_test))\n",
    "\n",
    "# split the data into training and testing sets. Change the seed value to obtain different random splits.\n",
    "seed = 4\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=seed,stratify=y)\n",
    "\n",
    "print(\"Training data shape: \",X_train.shape)\n",
    "print(\"Testing data shape: \",X_test.shape)\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSFEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of of pandas dataframes corresponding to each sample\n",
    "X_train_dfs = [pd.DataFrame(sample, columns=['accx', 'accy', 'accz']) for sample in X_train]\n",
    "X_test_dfs = [pd.DataFrame(sample, columns=['accx', 'accy', 'accz']) for sample in X_test]\n",
    "\n",
    "X_train_dfs = [df.apply(lambda x: np.sqrt(x['accx']**2 + x['accy']**2 + x['accz']**2), axis=1) for df in X_train_dfs]\n",
    "X_test_dfs = [df.apply(lambda x: np.sqrt(x['accx']**2 + x['accy']**2 + x['accz']**2), axis=1) for df in X_test_dfs]\n",
    "\n",
    "# consider all features\n",
    "cfg_file = tsfel.get_features_by_domain()  \n",
    "\n",
    "# get list of feature vectors for each dataframe (or sample)           \n",
    "# choosing `fs=50` because the data was sampled at 50Hz                              \n",
    "X_train_tsfel_dfs = [tsfel.time_series_features_extractor(cfg_file, df, fs=50) for df in X_train_dfs]\n",
    "X_train_tsfel = pd.concat(X_train_tsfel_dfs, axis=0).fillna(0).values\n",
    "\n",
    "X_test_tsfel_dfs = [tsfel.time_series_features_extractor(cfg_file, df, fs=50) for df in X_test_dfs]\n",
    "X_test_tsfel = pd.concat(X_test_tsfel_dfs, axis=0).fillna(0).values\n",
    "\n",
    "# merge the list of dataframes into a single dataframe\n",
    "col = X_train_tsfel_dfs[0].columns\n",
    "X_train_tsfel_df = pd.DataFrame(X_train_tsfel, columns = col)\n",
    "X_test_tsfel_df = pd.DataFrame(X_test_tsfel, columns = col)\n",
    "\n",
    "# do the following for the training data and then choose remaining columns from the test data\n",
    "# remove columns where the feature is constant throughout all samples\n",
    "for col in X_train_tsfel_df.columns:\n",
    "    if len(X_train_tsfel_df[col].unique()) == 1:\n",
    "        X_train_tsfel_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# remove highly correlated features (columns) from the training data\n",
    "corr = X_train_tsfel_df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "tri_df = corr.mask(mask)\n",
    "to_drop = [c for c in tri_df.columns if any(tri_df[c] > 0.9)] # threshold = 0.9\n",
    "X_train_tsfel_df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# remove the same columns from the test data\n",
    "X_test_tsfel_df = X_test_tsfel_df[X_train_tsfel_df.columns] \n",
    "\n",
    "# Filter columns starting with '0_FFT mean coefficient_'\n",
    "filtered_cols = [col for col in X_train_tsfel_df.columns if col.startswith('0_FFT mean coefficient_')]\n",
    "# Calculate the sum of squares for the filtered columns to get energy\n",
    "X_train_tsfel_df['0_Energy'] = X_train_tsfel_df[filtered_cols].pow(2).sum(axis=1)\n",
    "X_test_tsfel_df['0_Energy'] = X_test_tsfel_df[filtered_cols].pow(2).sum(axis=1)\n",
    "# Drop the filtered columns\n",
    "X_train_tsfel_df.drop(filtered_cols, axis=1, inplace=True)\n",
    "X_test_tsfel_df.drop(filtered_cols, axis=1, inplace=True)\n",
    "\n",
    "# feature selection\n",
    "features = ['0_Autocorrelation', '0_Centroid', '0_Energy', '0_Kurtosis', '0_Max power spectrum', '0_Mean', '0_Mean diff', '0_Median',\n",
    "       '0_Median diff', '0_Neighbourhood peaks', '0_Power bandwidth',\n",
    "       '0_Skewness', '0_Slope', '0_Spectral distance', '0_Spectral entropy',\n",
    "       '0_Spectral positive turning points', '0_Spectral skewness',\n",
    "       '0_Spectral variation', '0_Wavelet absolute mean_8',\n",
    "       '0_Wavelet entropy', '0_Wavelet variance_8']\n",
    "\n",
    "X_train_tsfel_df = X_train_tsfel_df[features]\n",
    "X_test_tsfel_df = X_test_tsfel_df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot vs Few Shot: A Qualitative Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {1: \"WALKING\", 2: \"WALKING_UPSTAIRS\", 3: \"WALKING_DOWNSTAIRS\", 4: \"SITTING\", 5: \"STANDING\", 6: \"LAYING\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the LLM with Zero Shot prompting on 5 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_Autocorrelation': 4.0,\n",
       " '0_Centroid': 4.985172868880233,\n",
       " '0_Energy': 0.04403701574107831,\n",
       " '0_Kurtosis': -0.5375661524976398,\n",
       " '0_Max power spectrum': 3.604770415927572,\n",
       " '0_Mean': 1.049793479716819,\n",
       " '0_Mean diff': 4.5496276621879624e-05,\n",
       " '0_Median': 1.0186349478511663,\n",
       " '0_Median diff': 0.0129247391665257,\n",
       " '0_Neighbourhood peaks': 17.0,\n",
       " '0_Power bandwidth': 5.1000000000000005,\n",
       " '0_Skewness': 0.2921059091342811,\n",
       " '0_Slope': 5.547106249216689e-06,\n",
       " '0_Spectral distance': -104143.19960980392,\n",
       " '0_Spectral entropy': 0.492597392267046,\n",
       " '0_Spectral positive turning points': 78.0,\n",
       " '0_Spectral skewness': 2.0376811420807743,\n",
       " '0_Spectral variation': 0.8573145527149457,\n",
       " '0_Wavelet absolute mean_8': 0.09370415452419341,\n",
       " '0_Wavelet entropy': 2.0598362590465467,\n",
       " '0_Wavelet variance_8': 0.512597258494216}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tsfel_df.loc[5].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided TSFEL feature vector, I would classify the activity as: 4: SITTING.\n",
      "\n",
      "The reasoning behind this classification is as follows:\n",
      "\n",
      "- The '0_Mean' and '0_Median' values are close to 1, indicating a relatively stable acceleration signal, which is consistent with sitting.\n",
      "- The '0_Energy' value is very low, indicating a low level of movement, which is also consistent with sitting.\n",
      "- The '0_Spectral entropy' value is close to 1, indicating a relatively low level of complexity in the signal, which is consistent with sitting.\n",
      "- The '0_Wavelet absolute mean_8' and '0_Wavelet variance_8' values are relatively low, indicating a low level of movement and variability in the signal, which is consistent with sitting.\n",
      "\n",
      "Overall, the feature vector suggests a relatively stable and low-movement activity, which is most consistent with sitting.\n",
      "--------------------------------\n",
      "Actual Activity - 4: SITTING\n",
      "===============================================\n",
      "Based on the provided TSFEL feature vector, I would classify the activity as: 1: WALKING\n",
      "--------------------------------\n",
      "Actual Activity - 4: SITTING\n",
      "===============================================\n",
      "Based on the provided TSFEL feature vector, I would classify the activity as: 1: WALKING\n",
      "--------------------------------\n",
      "Actual Activity - 3: WALKING_DOWNSTAIRS\n",
      "===============================================\n",
      "Based on the provided TSFEL feature vector, I would classify the activity as: 1: WALKING\n",
      "--------------------------------\n",
      "Actual Activity - 2: WALKING_UPSTAIRS\n",
      "===============================================\n",
      "Based on the provided TSFEL feature vector, I would classify the activity as: 1: WALKING\n",
      "--------------------------------\n",
      "Actual Activity - 6: LAYING\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(0, 54, 5):\n",
    "    query = f\"*Your task is to classify the activity performed by the user based on the provided featurized accelerometer data.\\n* The data is in the form of a TSFEL feature vector with features: {features}.\\n* There are six possible activities: 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING\\n\\nWhat is this activity: {X_test_tsfel_df.loc[i].to_dict()}?\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            # Set an optional system message. This sets the behavior of the\n",
    "            # assistant and can be used to provide specific instructions for\n",
    "            # how it should behave throughout the conversation.\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an activity classification model who will classify an activity based on provided TSFEL feature vector. Keep responses in the following format: 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING\"\n",
    "            },\n",
    "            # Set a user message for the assistant to respond to.\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        # The language model which will generate the completion.\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "\n",
    "        # optional parameters\n",
    "\n",
    "        # Controls randomness: lowering results in less random completions.\n",
    "        temperature=0,\n",
    "    )\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "    print(\"--------------------------------\")\n",
    "    print(f\"Actual Activity - {y_test[i]}: {label[y_test[i]]}\")\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the LLM gets 1 out of 5 correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test the LLM on 5 random samples from the test set and few Shot by giving it 10 random examples from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: WALKING\n",
      "--------------------------------\n",
      "Actual Activity - 1: WALKING\n",
      "===============================================\n",
      "1: WALKING\n",
      "--------------------------------\n",
      "Actual Activity - 1: WALKING\n",
      "===============================================\n",
      "4: SITTING\n",
      "--------------------------------\n",
      "Actual Activity - 5: STANDING\n",
      "===============================================\n",
      "1: WALKING\n",
      "--------------------------------\n",
      "Actual Activity - 2: WALKING_UPSTAIRS\n",
      "===============================================\n",
      "3: WALKING_DOWNSTAIRS\n",
      "--------------------------------\n",
      "Actual Activity - 3: WALKING_DOWNSTAIRS\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "y_few_shot_pred_tup = []\n",
    "for i in np.random.randint(0, 54, 5):\n",
    "    query = f\"*Your task is to classify the activity performed by the user based on the provided featurized accelerometer data. \\n* The data is in the form of a TSFEL feature vector with features: {features} \\n* There are six possible activities - 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING.\\n* Please provide the most likely activity as a single integer corresponding to the activity.\\n Here are few examples with values corresponding to the given features:\"\n",
    "    # giving it random 10 examples from the training data\n",
    "    for j in np.random.randint(0, 126, 10):\n",
    "        query+=f\"{j+1}.\\n\"\n",
    "        query+=f\"TSFEL Feature vector = {list(X_train_tsfel_df.loc[j].to_dict().values())}\\n\"\n",
    "        query+=f\"Activity/Label = {y_train[j]}: {label[y_train[j]]}\\n\"\n",
    "        query+=\"\\n\"\n",
    "    query+=f\"\\nPredict the activity with the following feature vector: {X_test_tsfel_df.loc[i].to_dict().values()}.\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            # Set an optional system message. This sets the behavior of the\n",
    "            # assistant and can be used to provide specific instructions for\n",
    "            # how it should behave throughout the conversation.\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are an activity classification model. Keep responses in the following format: 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING. You should output a single integer corresponding to the activity label.\"\n",
    "            },\n",
    "            # Set a user message for the assistant to respond to.\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        # The language model which will generate the completion.\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        # optional parameters\n",
    "\n",
    "        # Controls randomness: lowering results in less random completions.\n",
    "        temperature=0,\n",
    "    )\n",
    "    T.sleep(2)\n",
    "    # append the completion returned by the LLM to y_pred\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "    print(\"--------------------------------\")\n",
    "    print(f\"Actual Activity - {y_test[i]}: {label[y_test[i]]}\")\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the LLM is correct 3 out of 5 times. Clearly few shot is better than zero shot here.\n",
    "This is largerly because the LLM now has context and it can better understand the feature vectors and patterns and adapt it predictions on new data accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.int64(50), '3: WALKING_DOWNSTAIRS')\n",
      "(np.int64(46), '1: WALKING')\n",
      "(np.int64(42), '1: WALKING')\n",
      "(np.int64(39), '5: STANDING')\n",
      "(np.int64(13), '6: LAYING')\n",
      "(np.int64(50), '3: WALKING_DOWNSTAIRS')\n",
      "(np.int64(39), '6: LAYING')\n",
      "(np.int64(7), '5: STANDING')\n",
      "(np.int64(10), '4: SITTING')\n",
      "(np.int64(6), '2: WALKING_UPSTAIRS')\n",
      "(np.int64(5), '1: WALKING')\n",
      "(np.int64(9), '2: WALKING_UPSTAIRS')\n",
      "(np.int64(5), '1: WALKING')\n",
      "(np.int64(44), '4: SITTING')\n",
      "(np.int64(46), '5: STANDING')\n",
      "(np.int64(51), '1: WALKING')\n",
      "(np.int64(19), '4: SITTING')\n",
      "(np.int64(24), '1: WALKING')\n",
      "(np.int64(16), '5: STANDING')\n",
      "(np.int64(36), '4: SITTING')\n",
      "(np.int64(2), '1: WALKING')\n",
      "(np.int64(49), '3: WALKING_DOWNSTAIRS')\n",
      "(np.int64(23), '1: WALKING')\n",
      "(np.int64(32), '4: SITTING')\n",
      "(np.int64(5), '1: WALKING')\n",
      "(np.int64(33), '4: SITTING')\n",
      "(np.int64(48), '3: WALKING_DOWNSTAIRS')\n"
     ]
    }
   ],
   "source": [
    "y_few_shot_pred_tup = []\n",
    "for i in np.random.randint(0, 54, 27):\n",
    "    query = f\"*Your task is to classify the activity performed by the user based on the provided featurized accelerometer data.\\n* The features are: {features}. \\n* You are given values corresponding to the features in order. \\n* There are six possible activities - 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING.\\n* Please provide the most likely activity as a single integer corresponding to the activity.\\n Here are few examples with values corresponding to the given features:\"\n",
    "    # giving it random 10 examples from the training data\n",
    "    for j in np.random.randint(0, 126, 10):\n",
    "        query+=f\"{j+1}.\\n\"\n",
    "        query+=f\"Feature vector = {list(X_train_tsfel_df.loc[j].to_dict().values())}\\n\"\n",
    "        query+=f\"Activity = {y_train[j]}: {label[y_train[j]]}\\n\"\n",
    "    query+=f\"\\nWhat is this activity: {list(X_test_tsfel_df.loc[i].to_dict().values())}?\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            # Set an optional system message. This sets the behavior of the\n",
    "            # assistant and can be used to provide specific instructions for\n",
    "            # how it should behave throughout the conversation.\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are an activity classification model. Keep responses in the following format: 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING. You should output a single integer corresponding to the activity label.\"\n",
    "            },\n",
    "            # Set a user message for the assistant to respond to.\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        # The language model which will generate the completion.\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        # optional parameters\n",
    "\n",
    "        # Controls randomness: lowering results in less random completions.\n",
    "        temperature=0,\n",
    "    )\n",
    "    T.sleep(2)\n",
    "    # append the completion returned by the LLM to y_pred\n",
    "    y_few_shot_pred_tup.append((i,chat_completion.choices[0].message.content))\n",
    "    print(y_few_shot_pred_tup[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_test = [int(y_test[int(x[0])]) for x in y_few_shot_pred_tup]\n",
    "y_pred = [int(x[1][0]) for x in y_few_shot_pred_tup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5925925925925926"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(new_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Decision Tree Classifier and get predictions\n",
    "dtc_tsfel = DecisionTreeClassifier()\n",
    "dtc_tsfel.fit(X_train_tsfel, y_train)\n",
    "y_pred_tsfel = dtc_tsfel.predict(X_test_tsfel)\n",
    "acc_dt = accuracy_score(y_pred_tsfel, y_test)\n",
    "acc_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree clearly has better accuracy than the LLM. This is because the LLM is a language model and is not trained to predict the labels of the data. It is trained to predict the next word in a sentence given the previous words. The decision tree on the other hand is trained to predict the labels of the data. This is why the decision tree has better accuracy than the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of Zero-Shot Learning and Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since LLMs are large language models trained on text data, they may not be able to capture the complex temporal and spatial patterns present in sensor data, limiting their performance on activity recognition tasks. \n",
    "- Also they may not be able to differentiate between small variations in the data between two similar activities. \n",
    "- The patterns in the accelerometer data also depend on the individual and the environment, which may not be captured by the LLMs.\n",
    "- It might be the case that the LLM is trained in a different domain and context and might not understand the patterns in the accelerometer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# chose a random number between 1,6\n",
    "leave_out = np.random.randint(1,7)\n",
    "new_y_train = []\n",
    "valid_idx = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] != leave_out:\n",
    "        new_y_train.append(y_train[i])\n",
    "        valid_idx.append(i)\n",
    "print(leave_out)\n",
    "invalid_idx = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == leave_out:\n",
    "        invalid_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Left Out Activity Activity -  5 : STANDING\n",
      "---\n",
      "Prediction -  4: SITTING\n",
      "===============================================\n",
      "Prediction -  4: SITTING\n",
      "===============================================\n",
      "Prediction -  6: LAYING\n",
      "===============================================\n",
      "Prediction -  4: SITTING\n",
      "===============================================\n",
      "Prediction -  4: SITTING\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Left Out Activity Activity - \",leave_out,\":\",label[leave_out])\n",
    "print(\"---\")\n",
    "for i in random.sample(invalid_idx, 5):\n",
    "    query = f\"*Your task is to classify the activity performed by the user based on the provided featurized accelerometer data.\\n* The features are: {features}. \\n* You are given values corresponding to the features in order. \\n* There are six possible activities - 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING.\\n* Please provide the most likely activity as a single integer corresponding to the activity.\\n Here are few examples with values corresponding to the given features:\"\n",
    "    # giving it random 10 examples from the training data\n",
    "    for j in random.sample(valid_idx, 10):\n",
    "        query+=f\"{j+1}.\\n\"\n",
    "        query+=f\"Feature vector = {list(X_train_tsfel_df.loc[j].to_dict().values())}\\n\"\n",
    "        query+=f\"Activity = {y_train[j]}: {label[y_train[j]]}\\n\"\n",
    "    query+=f\"\\nWhat is this activity: {list(X_test_tsfel_df.loc[i].to_dict().values())}?\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            # Set an optional system message. This sets the behavior of the\n",
    "            # assistant and can be used to provide specific instructions for\n",
    "            # how it should behave throughout the conversation.\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are an activity classification model. Keep responses in the following format: 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING. You should output a single integer corresponding to the activity label.\"\n",
    "            },\n",
    "            # Set a user message for the assistant to respond to.\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        # The language model which will generate the completion.\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        # optional parameters\n",
    "\n",
    "        # Controls randomness: lowering results in less random completions.\n",
    "        temperature=0,\n",
    "    )\n",
    "    T.sleep(2)\n",
    "    # append the completion returned by the LLM to y_pred\n",
    "    print(f\"Prediction - \",chat_completion.choices[0].message.content)\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM is unable to classify the activity correctly because the LLM has not seen the activity before and does not have enough context to understand the patterns in the accelerometer data. The LLM is trained on a different domain and context and is not able to generalize to the unseen activity. The LLM is not able to differentiate between the unseen activity and the other activities in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM's Predicition: 2: WALKING_UPSTAIRS\n",
      "===============================================\n",
      "LLM's Predicition: 4: SITTING\n",
      "===============================================\n",
      "LLM's Predicition: 4: SITTING\n",
      "===============================================\n",
      "LLM's Predicition: 2: WALKING_UPSTAIRS\n",
      "===============================================\n",
      "LLM's Predicition: 1: WALKING\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(0, 54, 5):\n",
    "    query = f\"*Your task is to classify the activity performed by the user based on the provided featurized accelerometer data.\\n* The features are: {features}. \\n* You are given values corresponding to the features in order. \\n* There are six possible activities - 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING.\\n* Please provide the most likely activity as a single integer corresponding to the activity.\\n Here are few examples with values corresponding to the given features:\"\n",
    "    # giving it random 10 examples from the training data\n",
    "    for j in np.random.randint(0, 126, 10):\n",
    "        query+=f\"{j+1}.\\n\"\n",
    "        query+=f\"Feature vector = {list(X_train_tsfel_df.loc[j].to_dict().values())}\\n\"\n",
    "        query+=f\"Activity = {y_train[j]}: {label[y_train[j]]}\\n\"\n",
    "    query+=f\"\\nWhat is this activity: {[float(random.uniform(X_train_tsfel_df[feature].min(), X_train_tsfel_df[feature].max())) for feature in features]}?\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            # Set an optional system message. This sets the behavior of the\n",
    "            # assistant and can be used to provide specific instructions for\n",
    "            # how it should behave throughout the conversation.\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are an activity classification model. Keep responses in the following format: 1: WALKING, 2: WALKING_UPSTAIRS, 3: WALKING_DOWNSTAIRS, 4: SITTING, 5: STANDING, 6: LAYING. You should output a single integer corresponding to the activity label.\"\n",
    "            },\n",
    "            # Set a user message for the assistant to respond to.\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        # The language model which will generate the completion.\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        # optional parameters\n",
    "\n",
    "        # Controls randomness: lowering results in less random completions.\n",
    "        temperature=0,\n",
    "    )\n",
    "    T.sleep(2)\n",
    "    # append the completion returned by the LLM to y_pred\n",
    "    print(f\"LLM's Predicition: {chat_completion.choices[0].message.content}\")\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM is making some predictions on the random feature vector it is fed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_es335_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
